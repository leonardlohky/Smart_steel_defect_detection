{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "#! pip install segmentation-models\n",
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models\n",
    "print(segmentation_models.__version__)\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rle import mask2rle, rle2mask, area\n",
    "from model_metric import dice_coef, recall_m, precision_m, f1_score_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder check ['0abfbfc69.jpg', '0ac9936af.jpg'] \n",
      "\n",
      "Output folder check ['.ipynb_checkpoints', 'archive', 'defect_report.csv'] \n",
      "\n",
      "Model folder check ['severstal_binary.h5', 'severstal_segmentation_Defect_1.h5', 'severstal_segmentation_Defect_2.h5', 'severstal_segmentation_Defect_3.h5', 'severstal_segmentation_Defect_4.h5'] \n",
      "\n",
      "Archive folder check ['.ipynb_checkpoints'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_folder = '../Input/'\n",
    "print('Input folder check', os.listdir(input_folder),'\\n')\n",
    "output_folder = '../Output/'\n",
    "print('Output folder check', os.listdir(output_folder),'\\n')\n",
    "model_folder = '../Model/'\n",
    "print('Model folder check', os.listdir(model_folder),'\\n')\n",
    "archieve_folder = '../Output/archive/'\n",
    "print('Archive folder check', os.listdir(archieve_folder),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(input_folder):\n",
    "\n",
    "    #read all file from train_folder\n",
    "    img_files = os.listdir(input_folder)\n",
    "    file_list = []\n",
    "\n",
    "    if len(img_files)>0:\n",
    "        print('Number of new image files detected:', len(img_files))\n",
    "        print('List of image file', img_files)\n",
    "        \n",
    "        for file in img_files:\n",
    "            \n",
    "            file_list.append(file)\n",
    "            output_df = pd.DataFrame(file_list, columns = ['ImageId'])\n",
    "        \n",
    "    else:\n",
    "        print('No file inside input folder')\n",
    "               \n",
    "    return(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new image files detected: 2\n",
      "List of image file ['0abfbfc69.jpg', '0ac9936af.jpg']\n"
     ]
    }
   ],
   "source": [
    "X = data_prep(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class img_array_gen(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size = 1, image_path = input_folder, preprocess=None, info={}):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocess = preprocess\n",
    "        self.info = info\n",
    "        self.data_path = image_path\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        '''\n",
    "        The DataGenerator takes ImageIds of batch size 1 and returns Image array to the model.\n",
    "        With the help of ImageIds the DataGenerator locates the Image file in the path, the image is read and resized from\n",
    "        256x1600 to 256x800.\n",
    "        '''\n",
    "        X = np.empty((self.batch_size,256,800,3),dtype=np.float32)\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n",
    "            self.info[index*self.batch_size+i]=f\n",
    "            X[i,] = Image.open(self.data_path + f).resize((800,256))      \n",
    "        if self.preprocess!=None: X = self.preprocess(X)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded\n"
     ]
    }
   ],
   "source": [
    "dependencies = {\n",
    "                'recall_m':recall_m,\n",
    "                'precision_m':precision_m,\n",
    "                'dice_coef':dice_coef,\n",
    "                'f1_score_m':f1_score_m,\n",
    "                'dice_loss':sm.losses.dice_loss\n",
    "                }\n",
    "\n",
    "defect_model = load_model('../Model/Defect_model.h5', custom_objects=dependencies)\n",
    "type1_model = load_model('../Model/Defect_type1_model.h5', custom_objects=dependencies)\n",
    "type2_model = load_model('../Model/Defect_type2_model.h5', custom_objects=dependencies)\n",
    "type3_model = load_model('../Model/Defect_type3_model.h5', custom_objects=dependencies)\n",
    "type4_model = load_model('../Model/Defect_type4_model.h5', custom_objects=dependencies)\n",
    "\n",
    "print(\"Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_pred(df):\n",
    "    '''\n",
    "    Input: ImageIds in form of a dataframe\n",
    "    Return: Predictions of classification models\n",
    "    '''\n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "    img_file = ImageDataGenerator(rescale=1./255).flow_from_dataframe(dataframe=df, \n",
    "                                                                      directory='../Input/', \n",
    "                                                                      x_col=\"ImageId\", \n",
    "                                                                      class_mode = None, \n",
    "                                                                      target_size=(256,512), \n",
    "                                                                      batch_size=1, \n",
    "                                                                      shuffle=False)\n",
    "\n",
    "    defect_pred = defect_model.predict(img_file, verbose=0)\n",
    "    defect_status = pd.DataFrame(defect_pred, columns = ['hasDefect'])\n",
    "    defect_status['hasDefect'] = np.where(defect_pred>0.6,1,0)\n",
    "    defect_status['ImageId'] = df['ImageId']\n",
    "    return defect_status[['ImageId', 'hasDefect']]\n",
    "\n",
    "def seg_pred(df):\n",
    "    '''\n",
    "    Input: ImageIds in form of a dataframe\n",
    "    Return: Predictions of segmentation models\n",
    "    '''\n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "    preprocess = get_preprocessing('efficientnetb1')\n",
    "    tmp=[]\n",
    "    loop_num = 50\n",
    "    \n",
    "    for j in range((len(df)//loop_num)+1):\n",
    "        img_seg = df[loop_num*j:loop_num*j+loop_num]\n",
    "        img_array =  img_array_gen(img_seg, preprocess=preprocess)\n",
    "        model1_pred = type1_model.predict(img_array,verbose=0)\n",
    "        model2_pred = type2_model.predict(img_array,verbose=0)\n",
    "        model3_pred = type3_model.predict(img_array,verbose=0)\n",
    "        model4_pred = type4_model.predict(img_array,verbose=0)\n",
    "        \n",
    "        for i in range(len(model1_pred)):\n",
    "            type1 = mask2rle(np.array((Image.fromarray((model1_pred[i][:,:,0])>=0.5)).resize((1600,256))).astype(int))\n",
    "            type2 = mask2rle(np.array((Image.fromarray((model2_pred[i][:,:,0])>=0.5)).resize((1600,256))).astype(int))\n",
    "            type3 = mask2rle(np.array((Image.fromarray((model3_pred[i][:,:,0])>=0.5)).resize((1600,256))).astype(int))\n",
    "            type4 = mask2rle(np.array((Image.fromarray((model4_pred[i][:,:,0])>=0.5)).resize((1600,256))).astype(int))\n",
    "            \n",
    "            tmp.append([img_seg.ImageId.iloc[i],type1,type2,type3,type4])\n",
    "    \n",
    "    seg_df = pd.DataFrame(tmp,columns=['ImageId','EncodedPixels_1','EncodedPixels_2','EncodedPixels_3','EncodedPixels_4'])            \n",
    "\n",
    "    return(seg_df)\n",
    "\n",
    "def comb_pred(df):\n",
    "    '''\n",
    "    Input: ImageId (dataframe)\n",
    "    Return: Comdined dataframe of output of pred_classification function and pred_segmentation function\n",
    "    '''\n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "    merge_df = class_pred(df).merge(seg_pred(df),on=['ImageId'])\n",
    "    \n",
    "    def_list = ['Defect_1', 'Defect_2', 'Defect_3', 'Defect_4']\n",
    "\n",
    "    for defect, i in zip(def_list, (range(1,5))):\n",
    "        \n",
    "        merge_df[defect] = merge_df['EncodedPixels_{}'.format(i)].str.count(' ')\n",
    "        merge_df['Defect_{}'.format(i)] = (np.where((merge_df['Defect_{}'.format(i)]>0),i,0))\n",
    "\n",
    "    merge_df[def_list] = merge_df[def_list].replace(0,'')\n",
    "    merge_df['Defect_Type'] = merge_df.filter(regex='Defect_[1-4]').astype(str).apply(lambda x: x.str.cat(), axis=1)\n",
    "    merge_df = merge_df.drop(columns=def_list)\n",
    "    \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 validated image filenames.\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002430AE12558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>hasDefect</th>\n",
       "      <th>EncodedPixels_1</th>\n",
       "      <th>EncodedPixels_2</th>\n",
       "      <th>EncodedPixels_3</th>\n",
       "      <th>EncodedPixels_4</th>\n",
       "      <th>Defect_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abfbfc69.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>6394 5 6650 5 6905 5 7161 5 97387 10 97643 10 ...</td>\n",
       "      <td>652 14 908 14 1150 70 1406 70 1659 77 1915 77 ...</td>\n",
       "      <td>142446 1 142702 1 142956 6 143212 6 143467 8 1...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ac9936af.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>341104 36 341360 36 341613 46 341869 46 342123...</td>\n",
       "      <td></td>\n",
       "      <td>339060 53 339316 53 339547 90 339803 90 340057...</td>\n",
       "      <td>339040 3 339046 111 339296 3 339302 111 339542...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  hasDefect  \\\n",
       "0  0abfbfc69.jpg          1   \n",
       "1  0ac9936af.jpg          1   \n",
       "\n",
       "                                     EncodedPixels_1  \\\n",
       "0                                                      \n",
       "1  341104 36 341360 36 341613 46 341869 46 342123...   \n",
       "\n",
       "                                     EncodedPixels_2  \\\n",
       "0  6394 5 6650 5 6905 5 7161 5 97387 10 97643 10 ...   \n",
       "1                                                      \n",
       "\n",
       "                                     EncodedPixels_3  \\\n",
       "0  652 14 908 14 1150 70 1406 70 1659 77 1915 77 ...   \n",
       "1  339060 53 339316 53 339547 90 339803 90 340057...   \n",
       "\n",
       "                                     EncodedPixels_4 Defect_Type  \n",
       "0  142446 1 142702 1 142956 6 143212 6 143467 8 1...         234  \n",
       "1  339040 3 339046 111 339296 3 339302 111 339542...         134  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = comb_pred(X)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(df):\n",
    "\n",
    "    def img_report(df):\n",
    "\n",
    "        col_name = ['Timestamp', 'ImageId', 'hasDefect', 'Defect_Type']\n",
    "\n",
    "        dateTimeObj = datetime.now()\n",
    "        timestampStr = dateTimeObj.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "        print('Current Timestamp : ', timestampStr)\n",
    "\n",
    "        df['Timestamp'] = timestampStr\n",
    "        df = df[col_name].copy()\n",
    "\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                record = pd.read_csv(output_folder + 'defect_report.csv')           \n",
    "                print('Read record from defect_report.csv')  \n",
    "\n",
    "                record_img = list(record['ImageId'])\n",
    "                new_img = list(df['ImageId'])\n",
    "\n",
    "                for img in new_img:\n",
    "                    if img in record_img:\n",
    "                        print(img,'found in previous record')\n",
    "\n",
    "                #remove row if record already found in report\n",
    "                df = df[~df['ImageId'].isin(record_img)]\n",
    "                record = record.append(df)\n",
    "                record.to_csv(output_folder + 'defect_report.csv', index=False)\n",
    "\n",
    "                if len(df)<1:\n",
    "                    print('No data to update')\n",
    "                else:\n",
    "                    print('Report updated with latest data')\n",
    "\n",
    "                return\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print('defect_report.csv not found in folder')\n",
    "                new_df = pd.DataFrame(columns = col_name)\n",
    "                new_df = new_df.append(df)\n",
    "                new_df.to_csv(output_folder + 'defect_report.csv', index=False)\n",
    "                print('Created defect_report.csv with latest data')\n",
    "\n",
    "                break\n",
    "\n",
    "    def archive_img():\n",
    "        \n",
    "        record = pd.read_csv(output_folder + 'defect_report.csv')           \n",
    "        record_img = list(record['ImageId'])\n",
    "                \n",
    "        for top, dirs, files in os.walk(input_folder):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.jpg'):\n",
    "                    continue\n",
    "                file_path = os.path.join(top, filename)\n",
    "                if filename in record_img:\n",
    "                    shutil.move(file_path, os.path.join(archieve_folder, filename))    \n",
    "        \n",
    "        print('Scoring completed, image file(s) moved to archieve folder')\n",
    "\n",
    "    img_report(df)\n",
    "    archive_img()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Timestamp :  17-Oct-2020 00:26:35\n",
      "Read record from defect_report.csv\n",
      "0abfbfc69.jpg found in previous record\n",
      "0ac9936af.jpg found in previous record\n",
      "No data to update\n",
      "Scoring completed, image file(s) moved to archieve folder\n"
     ]
    }
   ],
   "source": [
    "post_processing(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steel_prediction(df):\n",
    "    '''\n",
    "    Function-1:\n",
    "    Input: ImageId(dataframe)\n",
    "    Process: Calls pred_combined which calls pred_classification and pred_segmentation\n",
    "            Applies thresholds -> area and classification probability\n",
    "    Return: DataFrame (columns = ImageId_ClassId,EncodedPixels)\n",
    "    \n",
    "    '''\n",
    "    df = df.drop(columns=['Defect_Type','Timestamp'])\n",
    "    df = df.reset_index().drop('index',axis=1)\n",
    "\n",
    "    tmp = []\n",
    "    for i in range(len(df)):      \n",
    "        imgid, defect, type1, type2, type3, type4 = df.iloc[i]  \n",
    "        # j, b, m1, m2, m3, m4, ep1, ep2, ep3, ep4 = p.iloc[i]\n",
    "        # randomly selected classification threshold values to get high recall \n",
    "        # for no defect binary classifier and high precision for multi-label classifier \n",
    "        # while not compromising much on other metrics\n",
    "        \n",
    "        # area thresholds are determined from EDA performed only on train dataset\n",
    "        if area(type1)>=500 and area(type1)<=15500 and defect>=0.95: \n",
    "            tmp.append([imgid+'_1',type1])\n",
    "        else:\n",
    "            tmp.append([imgid+'_1',''])\n",
    "\n",
    "        if area(type2)>=700 and area(type2)<=10000 and defect>=0.855:\n",
    "            tmp.append([imgid+'_2',type2])\n",
    "        else:\n",
    "            tmp.append([imgid+'_2',''])\n",
    "\n",
    "        if area(type3)>=1100 and area(type3)<=160000 and defect>=0.85:\n",
    "            tmp.append([imgid+'_3',type3])\n",
    "        else:\n",
    "            tmp.append([imgid+'_3',''])\n",
    "            \n",
    "        if area(type4)>=2800 and area(type4)<=127000 and defect>=0.85:\n",
    "            tmp.append([imgid+'_4',type4])\n",
    "        else:\n",
    "            tmp.append([imgid+'_4',''])\n",
    "            \n",
    "    return pd.DataFrame(tmp, columns = ['ImageId_ClassId','EncodedPixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abfbfc69.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0abfbfc69.jpg_2</td>\n",
       "      <td>6394 5 6650 5 6905 5 7161 5 97387 10 97643 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0abfbfc69.jpg_3</td>\n",
       "      <td>652 14 908 14 1150 70 1406 70 1659 77 1915 77 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0abfbfc69.jpg_4</td>\n",
       "      <td>142446 1 142702 1 142956 6 143212 6 143467 8 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ac9936af.jpg_1</td>\n",
       "      <td>341104 36 341360 36 341613 46 341869 46 342123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0ac9936af.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0ac9936af.jpg_3</td>\n",
       "      <td>339060 53 339316 53 339547 90 339803 90 340057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0ac9936af.jpg_4</td>\n",
       "      <td>339040 3 339046 111 339296 3 339302 111 339542...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0abfbfc69.jpg_1                                                   \n",
       "1  0abfbfc69.jpg_2  6394 5 6650 5 6905 5 7161 5 97387 10 97643 10 ...\n",
       "2  0abfbfc69.jpg_3  652 14 908 14 1150 70 1406 70 1659 77 1915 77 ...\n",
       "3  0abfbfc69.jpg_4  142446 1 142702 1 142956 6 143212 6 143467 8 1...\n",
       "4  0ac9936af.jpg_1  341104 36 341360 36 341613 46 341869 46 342123...\n",
       "5  0ac9936af.jpg_2                                                   \n",
       "6  0ac9936af.jpg_3  339060 53 339316 53 339547 90 339803 90 340057...\n",
       "7  0ac9936af.jpg_4  339040 3 339046 111 339296 3 339302 111 339542..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction = steel_prediction(final_df)\n",
    "final_prediction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
